{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80f2d597-03f8-4887-aa01-862c935f9045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ SparkSession creada\n"
     ]
    }
   ],
   "source": [
    "# Celda 1\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"Simple_Processing\") \\\n",
    "    .config(\"spark.driver.memory\", \"2g\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "print(\"✅ SparkSession creada\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "484622b3-5f1b-4ff1-8d33-60c3ea646419",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 Datos leídos exitosamente\n"
     ]
    }
   ],
   "source": [
    "# Celda 2: Leer los datos \n",
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .option(\"encoding\", \"UTF-8\") \\\n",
    "    .csv(\"Data/*.csv\")\n",
    "\n",
    "print(\"📚 Datos leídos exitosamente\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e48af0e-ac35-444e-94ec-6f372c41f1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Schema del MEF definido con 63 columnas\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType\n",
    "\n",
    "# Schema explícito basado en el diccionario de datos del MEF\n",
    "mef_schema = StructType([\n",
    "    StructField(\"ANO_EJE\", IntegerType(), True),\n",
    "    StructField(\"MES_EJE\", IntegerType(), True),\n",
    "    StructField(\"NIVEL_GOBIERNO\", StringType(), True),\n",
    "    StructField(\"NIVEL_GOBIERNO_NOMBRE\", StringType(), True),\n",
    "    StructField(\"SECTOR\", StringType(), True),\n",
    "    StructField(\"SECTOR_NOMBRE\", StringType(), True),\n",
    "    StructField(\"PLIEGO\", StringType(), True),\n",
    "    StructField(\"PLIEGO_NOMBRE\", StringType(), True),\n",
    "    StructField(\"SEC_EJEC\", IntegerType(), True),\n",
    "    StructField(\"EJECUTORA\", IntegerType(), True),\n",
    "    StructField(\"EJECUTORA_NOMBRE\", StringType(), True),\n",
    "    StructField(\"DEPARTAMENTO_EJECUTORA\", IntegerType(), True),\n",
    "    StructField(\"DEPARTAMENTO_EJECUTORA_NOMBRE\", StringType(), True),\n",
    "    StructField(\"PROVINCIA_EJECUTORA\", IntegerType(), True),\n",
    "    StructField(\"PROVINCIA_EJECUTORA_NOMBRE\", StringType(), True),\n",
    "    StructField(\"DISTRITO_EJECUTORA\", IntegerType(), True),\n",
    "    StructField(\"DISTRITO_EJECUTORA_NOMBRE\", StringType(), True),\n",
    "    StructField(\"SEC_FUNC\", IntegerType(), True),\n",
    "    StructField(\"PROGRAMA_PPTO\", IntegerType(), True),\n",
    "    StructField(\"PROGRAMA_PPTO_NOMBRE\", StringType(), True),\n",
    "    StructField(\"TIPO_ACT_PROY\", IntegerType(), True),\n",
    "    StructField(\"TIPO_ACT_PROY_NOMBRE\", StringType(), True),\n",
    "    StructField(\"PRODUCTO_PROYECTO\", IntegerType(), True),\n",
    "    StructField(\"PRODUCTO_PROYECTO_NOMBRE\", StringType(), True),\n",
    "    StructField(\"ACTIVIDAD_ACCION_OBRA\", IntegerType(), True),\n",
    "    StructField(\"ACTIVIDAD_ACCION_OBRA_NOMBRE\", StringType(), True),\n",
    "    StructField(\"FUNCION\", IntegerType(), True),\n",
    "    StructField(\"FUNCION_NOMBRE\", StringType(), True),\n",
    "    StructField(\"DIVISION_FUNCIONAL\", IntegerType(), True),\n",
    "    StructField(\"DIVISION_FUNCIONAL_NOMBRE\", StringType(), True),\n",
    "    StructField(\"GRUPO_FUNCIONAL\", IntegerType(), True),\n",
    "    StructField(\"GRUPO_FUNCIONAL_NOMBRE\", StringType(), True),\n",
    "    StructField(\"META\", IntegerType(), True),\n",
    "    StructField(\"FINALIDAD\", IntegerType(), True),\n",
    "    StructField(\"META_NOMBRE\", StringType(), True),\n",
    "    StructField(\"DEPARTAMENTO_META\", IntegerType(), True),\n",
    "    StructField(\"DEPARTAMENTO_META_NOMBRE\", StringType(), True),\n",
    "    StructField(\"FUENTE_FINANCIAMIENTO\", IntegerType(), True),\n",
    "    StructField(\"FUENTE_FINANCIAMIENTO_NOMBRE\", StringType(), True),\n",
    "    StructField(\"RUBRO\", IntegerType(), True),\n",
    "    StructField(\"RUBRO_NOMBRE\", StringType(), True),\n",
    "    StructField(\"TIPO_RECURSO\", StringType(), True),\n",
    "    StructField(\"TIPO_RECURSO_NOMBRE\", StringType(), True),\n",
    "    StructField(\"CATEGORIA_GASTO\", IntegerType(), True),\n",
    "    StructField(\"CATEGORIA_GASTO_NOMBRE\", StringType(), True),\n",
    "    StructField(\"TIPO_TRANSACCION\", IntegerType(), True),\n",
    "    StructField(\"GENERICA\", IntegerType(), True),\n",
    "    StructField(\"GENERICA_NOMBRE\", StringType(), True),\n",
    "    StructField(\"SUBGENERICA\", IntegerType(), True),\n",
    "    StructField(\"SUBGENERICA_NOMBRE\", StringType(), True),\n",
    "    StructField(\"SUBGENERICA_DET\", IntegerType(), True),\n",
    "    StructField(\"SUBGENERICA_DET_NOMBRE\", StringType(), True),\n",
    "    StructField(\"ESPECIFICA\", IntegerType(), True),\n",
    "    StructField(\"ESPECIFICA_NOMBRE\", StringType(), True),\n",
    "    StructField(\"ESPECIFICA_DET\", IntegerType(), True),\n",
    "    StructField(\"ESPECIFICA_DET_NOMBRE\", StringType(), True),\n",
    "    StructField(\"MONTO_PIA\", DoubleType(), True),\n",
    "    StructField(\"MONTO_PIM\", DoubleType(), True),\n",
    "    StructField(\"MONTO_CERTIFICADO\", DoubleType(), True),\n",
    "    StructField(\"MONTO_COMPROMETIDO_ANUAL\", DoubleType(), True),\n",
    "    StructField(\"MONTO_COMPROMETIDO\", DoubleType(), True),\n",
    "    StructField(\"MONTO_DEVENGADO\", DoubleType(), True),\n",
    "    StructField(\"MONTO_GIRADO\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "print(\"✅ Schema del MEF definido con 63 columnas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e1a082b-20e5-4546-8662-0df8401cf42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VALIDACIÓN CONTRA METADATA MEF\n",
      "============================================================\n",
      "📋 Columnas esperadas: 63\n",
      "📋 Columnas encontradas: 63\n",
      "✅ Columnas: CORRECTO\n",
      "🔑 Columnas clave faltantes: NINGUNA\n",
      "📅 Años encontrados: 2022, 2023, 2024, 2025\n"
     ]
    }
   ],
   "source": [
    "# Validación contra metadata esperada del MEF\n",
    "print(\"=\"*60)\n",
    "print(\"VALIDACIÓN CONTRA METADATA MEF\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Validar número de columnas\n",
    "expected_columns = 63  # Según schema MEF\n",
    "actual_columns = len(df.columns)\n",
    "print(f\"📋 Columnas esperadas: {expected_columns}\")\n",
    "print(f\"📋 Columnas encontradas: {actual_columns}\")\n",
    "print(f\"✅ Columnas: {'CORRECTO' if actual_columns == expected_columns else 'ERROR'}\")\n",
    "\n",
    "# 2. Validar presencia de columnas clave\n",
    "key_columns = [\"ANO_EJE\", \"MONTO_PIM\", \"MONTO_DEVENGADO\", \"PLIEGO\", \"SECTOR\"]\n",
    "missing_columns = [col for col in key_columns if col not in df.columns]\n",
    "print(f\"🔑 Columnas clave faltantes: {missing_columns if missing_columns else 'NINGUNA'}\")\n",
    "\n",
    "# 3. Validar años presentes\n",
    "if \"ANO_EJE\" in df.columns:\n",
    "    years = df.select(\"ANO_EJE\").distinct().collect()\n",
    "    year_list = [str(row['ANO_EJE']) for row in years]\n",
    "    print(f\"📅 Años encontrados: {', '.join(year_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d06273e-3ac1-4f06-bfa9-bbe3bef2ec08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "DETECCIÓN DE REGISTROS CORRUPTOS\n",
      "============================================================\n",
      "🚫 Registros con nulos en columnas críticas: 0\n",
      "📊 Porcentaje de completitud por columna:\n",
      "-RECORD 0-----------------\n",
      " ANO_EJE            | 1.0 \n",
      " EJECUTORA_NOMBRE   | 1.0 \n",
      " TIPO_ACT_PROY      | 1.0 \n",
      " GRUPO_FUNCIONAL    | 1.0 \n",
      " RUBRO_NOMBRE       | 1.0 \n",
      " SUBGENERICA_DET    | 1.0 \n",
      " MONTO_COMPROMETIDO | 1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Detección de registros corruptos/incompletos\n",
    "from pyspark.sql.functions import col, sum as spark_sum\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"DETECCIÓN DE REGISTROS CORRUPTOS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Registros con valores nulos en columnas críticas\n",
    "critical_nulls = df.filter(\n",
    "    col(\"ANO_EJE\").isNull() | \n",
    "    col(\"MONTO_PIM\").isNull() |\n",
    "    col(\"PLIEGO\").isNull()\n",
    ").count()\n",
    "print(f\"🚫 Registros con nulos en columnas críticas: {critical_nulls}\")\n",
    "\n",
    "# 2. Porcentaje de completitud por columna\n",
    "print(\"📊 Porcentaje de completitud por columna:\")\n",
    "completeness = df.select([\n",
    "    (1 - (spark_sum(col(c).isNull().cast(\"int\")) / df.count())).alias(c) \n",
    "    for c in df.columns[::10]  # Cada 10 columnas para no saturar\n",
    "])\n",
    "completeness.show(vertical=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58112cba-b414-49a8-b6da-f67940d85249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ELIMINACIÓN DE DUPLICADOS\n",
      "============================================================\n",
      "📊 Registros iniciales: 40,173,905\n",
      "🧹 Duplicados eliminados: 13\n",
      "✅ Registros finales: 40,173,892\n",
      "📉 Reducción: 0.00%\n"
     ]
    }
   ],
   "source": [
    "# Eliminar duplicados exactos\n",
    "initial_count = df.count()\n",
    "df_clean = df.dropDuplicates()\n",
    "final_count = df_clean.count()\n",
    "duplicates_removed = initial_count - final_count\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ELIMINACIÓN DE DUPLICADOS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"📊 Registros iniciales: {initial_count:,}\")\n",
    "print(f\"🧹 Duplicados eliminados: {duplicates_removed:,}\")\n",
    "print(f\"✅ Registros finales: {final_count:,}\")\n",
    "print(f\"📉 Reducción: {(duplicates_removed/initial_count*100):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99dd4262-fc98-4753-8b72-11988e9b9c15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ALMACENAMIENTO COMPLETADO\n",
      "============================================================\n",
      "💾 Datos guardados en formato Parquet\n",
      "🗂️  Estructura: data/raw/year=ANO_EJE/\n",
      "✅ Formato: Particionado por año (como solicita MEF)\n",
      "📋 Schema: Definición explícita según diccionario MEF\n"
     ]
    }
   ],
   "source": [
    "# Guardar particionado por año con estructura MEF\n",
    "df_clean.write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .partitionBy(\"ANO_EJE\") \\\n",
    "    .parquet(\"data/raw/year\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"ALMACENAMIENTO COMPLETADO\")\n",
    "print(\"=\"*60)\n",
    "print(\"💾 Datos guardados en formato Parquet\")\n",
    "print(\"🗂️  Estructura: data/raw/year=ANO_EJE/\")\n",
    "print(\"✅ Formato: Particionado por año (como solicita MEF)\")\n",
    "print(\"📋 Schema: Definición explícita según diccionario MEF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0274153f-7e05-4bd6-9042-8014a2618047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "VERIFICACIÓN FINAL FASE 1\n",
      "============================================================\n",
      "✅ Registros verificados: 40,173,892\n",
      "✅ Particiones: 800 archivos\n",
      "✅ Columnas: 63\n",
      "🎉 FASE 1 COMPLETADA EXITOSAMENTE\n"
     ]
    }
   ],
   "source": [
    "# Verificación final\n",
    "print(\"=\"*60)\n",
    "print(\"VERIFICACIÓN FINAL FASE 1\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Leer una partición para verificar\n",
    "df_verify = spark.read.parquet(\"data/raw/year\")\n",
    "print(f\"✅ Registros verificados: {df_verify.count():,}\")\n",
    "print(f\"✅ Particiones: {len(df_verify.inputFiles())} archivos\")\n",
    "print(f\"✅ Columnas: {len(df_verify.columns)}\")\n",
    "print(\"🎉 FASE 1 COMPLETADA EXITOSAMENTE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae483e7-42b1-4c95-87bc-12ffeb59c24c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
